#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
"""

import logging
import os
import tempfile
import re
import asyncio
from enum import Enum
from typing import Dict, Any, List, Optional, Tuple
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, Document
from telegram.ext import ContextTypes, ConversationHandler
from telegram.constants import ChatAction

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
import fitz  # PyMuPDF
from docx import Document as DocxDocument
import pytesseract
from PIL import Image
import PyPDF2

from ai_gigachat.client import gigachat_client

logger = logging.getLogger(__name__)


class AnalysisStates(Enum):
    """–°–æ—Å—Ç–æ—è–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    DOCUMENT_UPLOAD = 0
    ANALYSIS_TYPE_SELECTION = 1
    TEXT_PROCESSING = 2
    ANALYSIS_PROCESSING = 3
    RESULTS_REVIEW = 4
    ADDITIONAL_ACTIONS = 5


# –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ç–∏–ø—ã —Ñ–∞–π–ª–æ–≤
SUPPORTED_EXTENSIONS = {
    'document': ['.doc', '.docx', '.pdf'],
    'image': ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
}

# –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ (10 –ú–ë)
MAX_FILE_SIZE = 10 * 1024 * 1024

# –¢–∏–ø—ã –∞–Ω–∞–ª–∏–∑–∞ (—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –∫–ª—é—á–∞–º –≤ GigaChat –∫–ª–∏–µ–Ω—Ç–µ)
ANALYSIS_TYPES = {
    'law_compliance': {
        'name': '‚öñÔ∏è –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∑–∞–∫–æ–Ω—É',
        'description': '–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¥–µ–π—Å—Ç–≤—É—é—â–µ–º—É –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤—É –†–§',
        'icon': '‚öñÔ∏è'
    },
    'error_detection': {
        'name': 'üîç –ù–∞–π—Ç–∏ –æ—à–∏–±–∫–∏',
        'description': '–ü–æ–∏—Å–∫ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö, —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏ –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ',
        'icon': 'üîç'
    },
    'risk_assessment': {
        'name': '‚ö†Ô∏è –û—Ü–µ–Ω–∏—Ç—å —Ä–∏—Å–∫–∏',
        'description': '–ê–Ω–∞–ª–∏–∑ –ø—Ä–∞–≤–æ–≤—ã—Ö —Ä–∏—Å–∫–æ–≤ –∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º',
        'icon': '‚ö†Ô∏è'
    },
    'recommendations': {
        'name': 'üí° –î–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏',
        'description': '–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞',
        'icon': 'üí°'
    },
    'correspondence_analysis': {
        'name': 'üìß –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–µ—Ä–µ–ø–∏—Å–∫—É',
        'description': '–°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–µ–ª–æ–≤–æ–π –ø–µ—Ä–µ–ø–∏—Å–∫–∏ –∏ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–π',
        'icon': 'üìß'
    }
}


async def analyze_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /analyze - –Ω–∞—á–∞–ª–æ –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    """
    user = update.effective_user
    user_name = user.first_name if user.first_name else "–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å"
    
    # –û—á–∏—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ
    context.user_data.clear()
    
    welcome_text = (
        f"üìä **–ê–Ω–∞–ª–∏–∑ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤**\n\n"
        f"–ü—Ä–∏–≤–µ—Ç, {user_name}! –Ø –ø–æ–º–æ–≥—É –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–∞—à –¥–æ–∫—É–º–µ–Ω—Ç.\n\n"
        
        "üìã **–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:**\n"
        "‚Ä¢ **–î–æ–∫—É–º–µ–Ω—Ç—ã:** DOC, DOCX, PDF\n"
        "‚Ä¢ **–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:** JPG, PNG (—Å–∫–∞–Ω—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)\n"
        "‚Ä¢ **–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä:** 10 –ú–ë\n\n"
        
        "üéØ **–¢–∏–ø—ã –∞–Ω–∞–ª–∏–∑–∞:**\n"
        "‚Ä¢ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∑–∞–∫–æ–Ω—É\n"
        "‚Ä¢ –ü–æ–∏—Å–∫ –æ—à–∏–±–æ–∫ –∏ –Ω–µ–¥–æ—á–µ—Ç–æ–≤\n"
        "‚Ä¢ –û—Ü–µ–Ω–∫–∞ –ø—Ä–∞–≤–æ–≤—ã—Ö —Ä–∏—Å–∫–æ–≤\n"
        "‚Ä¢ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é\n"
        "‚Ä¢ –ê–Ω–∞–ª–∏–∑ –¥–µ–ª–æ–≤–æ–π –ø–µ—Ä–µ–ø–∏—Å–∫–∏\n\n"
        
        "üìé **–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:**"
    )
    
    keyboard = [
        [InlineKeyboardButton("‚ùå –û—Ç–º–µ–Ω–∞", callback_data="cancel_analysis")]
    ]
    
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Ç–∫—É–¥–∞ –ø—Ä–∏—à–µ–ª –∑–∞–ø—Ä–æ—Å
    if update.callback_query:
        await update.callback_query.answer()
        await update.callback_query.message.reply_text(
            welcome_text,
            reply_markup=reply_markup,
            parse_mode='Markdown'
        )
    else:
        await update.message.reply_text(
            welcome_text,
            reply_markup=reply_markup,
            parse_mode='Markdown'
        )
    
    return AnalysisStates.DOCUMENT_UPLOAD.value


async def handle_document_upload(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    """
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –æ–±—Ä–∞–±–æ—Ç–∫–∏
    await update.message.chat.send_action(ChatAction.TYPING)
    
    document = update.message.document
    photo = update.message.photo
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∑–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª
    if not document and not photo:
        await update.message.reply_text(
            "‚ùå **–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏**\n\n"
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç –≤ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ–º —Ñ–æ—Ä–º–∞—Ç–µ:\n"
            "‚Ä¢ DOC, DOCX, PDF - –¥–æ–∫—É–º–µ–Ω—Ç—ã\n"
            "‚Ä¢ JPG, PNG - –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (—Å–∫–∞–Ω—ã)\n\n"
            "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: 10 –ú–ë",
            parse_mode='Markdown'
        )
        return AnalysisStates.DOCUMENT_UPLOAD.value
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±—ã—á–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    if document:
        file_name = document.file_name
        file_size = document.file_size
        file_id = document.file_id
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        if file_size > MAX_FILE_SIZE:
            await update.message.reply_text(
                f"‚ùå **–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π**\n\n"
                f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size / (1024*1024):.1f} –ú–ë\n"
                f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: 10 –ú–ë\n\n"
                "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –º–µ–Ω—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞.",
                parse_mode='Markdown'
            )
            return AnalysisStates.DOCUMENT_UPLOAD.value
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
        file_extension = os.path.splitext(file_name.lower())[1]
        if file_extension not in SUPPORTED_EXTENSIONS['document']:
            await update.message.reply_text(
                f"‚ùå **–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç**\n\n"
                f"–§–∞–π–ª: `{file_name}`\n"
                f"–§–æ—Ä–º–∞—Ç: `{file_extension}`\n\n"
                "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:\n"
                "‚Ä¢ DOC, DOCX, PDF\n\n"
                "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –≤ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ–º —Ñ–æ—Ä–º–∞—Ç–µ.",
                parse_mode='Markdown'
            )
            return AnalysisStates.DOCUMENT_UPLOAD.value
        
        file_type = 'document'
        
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    else:  # photo
        # –ë–µ—Ä–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞–∏–ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
        photo_file = photo[-1]
        file_size = photo_file.file_size
        file_id = photo_file.file_id
        file_name = f"image_{photo_file.file_id}.jpg"
        file_extension = '.jpg'
        file_type = 'image'
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä
        if file_size > MAX_FILE_SIZE:
            await update.message.reply_text(
                f"‚ùå **–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ**\n\n"
                f"–†–∞–∑–º–µ—Ä: {file_size / (1024*1024):.1f} –ú–ë\n"
                f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: 10 –ú–ë\n\n"
                "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –º–µ–Ω—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞.",
                parse_mode='Markdown'
            )
            return AnalysisStates.DOCUMENT_UPLOAD.value
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ
    context.user_data['file_info'] = {
        'file_id': file_id,
        'file_name': file_name,
        'file_size': file_size,
        'file_extension': file_extension,
        'file_type': file_type
    }
    
    # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏
    success_text = (
        f"‚úÖ **–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω**\n\n"
        f"üìÑ **–§–∞–π–ª:** `{file_name}`\n"
        f"üìè **–†–∞–∑–º–µ—Ä:** {file_size / 1024:.1f} –ö–ë\n"
        f"üìù **–¢–∏–ø:** {'–î–æ–∫—É–º–µ–Ω—Ç' if file_type == 'document' else '–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (—Å–∫–∞–Ω)'}\n\n"
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞:"
    )
    
    # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å —Ç–∏–ø–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
    keyboard = []
    for analysis_type, info in ANALYSIS_TYPES.items():
        keyboard.append([InlineKeyboardButton(
            info['name'], 
            callback_data=f"analysis_type_{analysis_type}"
        )])
    
    keyboard.append([InlineKeyboardButton("‚ùå –û—Ç–º–µ–Ω–∞", callback_data="cancel_analysis")])
    
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await update.message.reply_text(
        success_text,
        reply_markup=reply_markup,
        parse_mode='Markdown'
    )
    
    return AnalysisStates.ANALYSIS_TYPE_SELECTION.value


async def handle_analysis_type_selection(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—ã–±–æ—Ä–∞ —Ç–∏–ø–∞ –∞–Ω–∞–ª–∏–∑–∞
    """
    query = update.callback_query
    await query.answer()
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞
    analysis_type = query.data.replace("analysis_type_", "")
    
    if analysis_type not in ANALYSIS_TYPES:
        await query.message.reply_text("‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞")
        return AnalysisStates.ANALYSIS_TYPE_SELECTION.value
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞
    context.user_data['analysis_type'] = analysis_type
    analysis_info = ANALYSIS_TYPES[analysis_type]
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –≤—ã–±–æ—Ä–∞
    confirmation_text = (
        f"üéØ **–í—ã–±—Ä–∞–Ω —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞:**\n\n"
        f"{analysis_info['icon']} **{analysis_info['name']}**\n\n"
        f"üìã {analysis_info['description']}\n\n"
        "‚è≥ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–æ–∫—É–º–µ–Ω—Ç–∞..."
    )
    
    await query.message.reply_text(
        confirmation_text,
        parse_mode='Markdown'
    )
    
    # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–µ–∫—Å—Ç–∞
    return await start_text_processing(update, context)


async def start_text_processing(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """
    –ù–∞—á–∞–ª–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    """
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –æ–±—Ä–∞–±–æ—Ç–∫–∏
    await update.callback_query.message.chat.send_action(ChatAction.TYPING)
    
    file_info = context.user_data['file_info']
    
    # –ö—Ä–∞—Å–∏–≤—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å-–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä
    processing_text = (
        f"üîÑ **–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞**\n\n"
        f"üìÑ **–§–∞–π–ª:** `{file_info['file_name']}`\n"
        f"üìè **–†–∞–∑–º–µ—Ä:** {file_info['file_size'] / 1024:.1f} –ö–ë\n"
        f"üìù **–¢–∏–ø:** {'–î–æ–∫—É–º–µ–Ω—Ç' if file_info['file_type'] == 'document' else '–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (—Å–∫–∞–Ω)'}\n\n"
        
        "üîç **–≠—Ç–∞–ø—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏:**\n"
        "‚ñ∂Ô∏è –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞...\n"
        "‚è∏Ô∏è –ê–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ\n"
        "‚è∏Ô∏è –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞\n\n"
        
        "‚è≥ *–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ...*"
    )
    
    progress_message = await update.callback_query.message.reply_text(
        processing_text,
        parse_mode='Markdown'
    )
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
    context.user_data['progress_message'] = progress_message
    
    try:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        extracted_text = await extract_text_from_file(file_info)
        
        if not extracted_text or len(extracted_text.strip()) < 10:
            await update.callback_query.message.reply_text(
                "‚ùå **–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞**\n\n"
                "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞. –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:\n"
                "‚Ä¢ –ü–ª–æ—Ö–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ —Å–∫–∞–Ω–∞\n"
                "‚Ä¢ –ü–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª\n"
                "‚Ä¢ –î–æ–∫—É–º–µ–Ω—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞\n\n"
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª.",
                parse_mode='Markdown'
            )
            return AnalysisStates.DOCUMENT_UPLOAD.value
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        context.user_data['extracted_text'] = extracted_text
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        progress_message = context.user_data.get('progress_message')
        if progress_message:
            updated_progress = (
                f"üîÑ **–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞**\n\n"
                f"üìÑ **–§–∞–π–ª:** `{file_info['file_name']}`\n"
                f"üìè **–†–∞–∑–º–µ—Ä:** {file_info['file_size'] / 1024:.1f} –ö–ë\n"
                f"üìù **–¢–∏–ø:** {'–î–æ–∫—É–º–µ–Ω—Ç' if file_info['file_type'] == 'document' else '–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (—Å–∫–∞–Ω)'}\n\n"
                
                "üîç **–≠—Ç–∞–ø—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏:**\n"
                "‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞\n"
                "‚ñ∂Ô∏è –ê–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ...\n"
                "‚è∏Ô∏è –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞\n\n"
                
                "‚è≥ *–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç...*"
            )
            
            try:
                await progress_message.edit_text(
                    updated_progress,
                    parse_mode='Markdown'
                )
            except Exception:
                pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫—Ä–∞—Ç–∫—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑–≤–ª–µ—á–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        words_count = len(extracted_text.split())
        chars_count = len(extracted_text)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
        if chars_count > 1000:
            quality_indicator = "üü¢ –û—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ"
        elif chars_count > 300:
            quality_indicator = "üü° –•–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ"
        else:
            quality_indicator = "üü† –£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ"
        
        stats_message = (
            f"‚úÖ **–¢–µ–∫—Å—Ç —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω**\n\n"
            f"üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è:**\n"
            f"‚Ä¢ **–°–∏–º–≤–æ–ª–æ–≤:** {chars_count:,}\n"
            f"‚Ä¢ **–°–ª–æ–≤:** {words_count:,}\n"
            f"‚Ä¢ **–ö–∞—á–µ—Å—Ç–≤–æ:** {quality_indicator}\n\n"
            "üß† –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –∞–Ω–∞–ª–∏–∑—É —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ..."
        )
        
        await update.callback_query.message.reply_text(
            stats_message,
            parse_mode='Markdown'
        )
        
        # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –∞–Ω–∞–ª–∏–∑—É
        return await start_analysis_processing(update, context)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞: {e}")
        await update.callback_query.message.reply_text(
            "‚ùå **–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞**\n\n"
            "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞.\n"
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ:\n"
            "‚Ä¢ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª –µ—â–µ —Ä–∞–∑\n"
            "‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥–æ–π —Ñ–æ—Ä–º–∞—Ç\n"
            "‚Ä¢ –û–±—Ä–∞—Ç–∏—Ç—å—Å—è –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É\n\n"
            "–î–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /analyze",
            parse_mode='Markdown'
        )
        return ConversationHandler.END


async def start_analysis_processing(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """
    –ù–∞—á–∞–ª–æ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ GigaChat
    """
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –æ–±—Ä–∞–±–æ—Ç–∫–∏
    await update.callback_query.message.chat.send_action(ChatAction.TYPING)
    
    analysis_type = context.user_data['analysis_type']
    extracted_text = context.user_data['extracted_text']
    analysis_info = ANALYSIS_TYPES[analysis_type]
    file_info = context.user_data['file_info']
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–≥—Ä–µ—Å—Å
    progress_message = context.user_data.get('progress_message')
    if progress_message:
        final_progress = (
            f"üîÑ **–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞**\n\n"
            f"üìÑ **–§–∞–π–ª:** `{file_info['file_name']}`\n"
            f"üìè **–†–∞–∑–º–µ—Ä:** {file_info['file_size'] / 1024:.1f} –ö–ë\n"
            f"üìù **–¢–∏–ø:** {'–î–æ–∫—É–º–µ–Ω—Ç' if file_info['file_type'] == 'document' else '–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (—Å–∫–∞–Ω)'}\n\n"
            
            "üîç **–≠—Ç–∞–ø—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏:**\n"
            "‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞\n"
            "‚úÖ –ê–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ\n"
            "‚ñ∂Ô∏è –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞...\n\n"
            
            "üß† *–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑...*"
        )
        
        try:
            await progress_message.edit_text(
                final_progress,
                parse_mode='Markdown'
            )
        except Exception:
            pass
    
    # –î–µ—Ç–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å –∞–Ω–∞–ª–∏–∑–∞
    analysis_status = (
        f"üß† **AI-–ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞**\n\n"
        f"{analysis_info['icon']} **{analysis_info['name']}**\n"
        f"üìÑ **–î–æ–∫—É–º–µ–Ω—Ç:** `{file_info['file_name']}`\n\n"
        
        "üîç **–ü—Ä–æ—Ü–µ—Å—Å –∞–Ω–∞–ª–∏–∑–∞:**\n"
        "‚ñ∂Ô∏è –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ GigaChat API...\n"
        "‚è∏Ô∏è –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤—É\n"
        "‚è∏Ô∏è –í—ã—è–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º –∏ —Ä–∏—Å–∫–æ–≤\n"
        "‚è∏Ô∏è –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π\n\n"
        
        "‚è≥ *–û–∂–∏–¥–∞–µ–º–æ–µ –≤—Ä–µ–º—è: 30-60 —Å–µ–∫—É–Ω–¥*\n"
        "ü§ñ *–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π AI-—é—Ä–∏—Å—Ç*"
    )
    
    analysis_message = await update.callback_query.message.reply_text(
        analysis_status,
        parse_mode='Markdown'
    )
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
    context.user_data['analysis_message'] = analysis_message
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞
        file_info = context.user_data['file_info']
        filename = file_info['file_name']
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ GigaChat
        analysis_result = await analyze_text_with_gigachat(analysis_type, extracted_text, filename)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        context.user_data['analysis_result'] = analysis_result
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        return await show_analysis_results(update, context)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
        await update.callback_query.message.reply_text(
            "‚ùå **–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞**\n\n"
            "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞.\n"
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ:\n"
            "‚Ä¢ –ü–æ–≤—Ç–æ—Ä–∏—Ç—å –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É\n"
            "‚Ä¢ –í—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥–æ–π —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞\n"
            "‚Ä¢ –û–±—Ä–∞—Ç–∏—Ç—å—Å—è –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É\n\n"
            "–ß—Ç–æ –¥–µ–ª–∞–µ–º –¥–∞–ª—å—à–µ?",
            parse_mode='Markdown'
        )
        return AnalysisStates.RESULTS_REVIEW.value


async def show_analysis_results(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """
    –ü–æ–∫–∞–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º
    """
    analysis_result = context.user_data['analysis_result']
    file_info = context.user_data['file_info']
    analysis_type = context.user_data['analysis_type']
    analysis_info = ANALYSIS_TYPES[analysis_type]
    
    # –ó–∞–≤–µ—Ä—à–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
    progress_message = context.user_data.get('progress_message')
    analysis_message = context.user_data.get('analysis_message')
    
    if progress_message:
        completion_status = (
            f"‚úÖ **–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞**\n\n"
            f"üìÑ **–§–∞–π–ª:** `{file_info['file_name']}`\n"
            f"üìè **–†–∞–∑–º–µ—Ä:** {file_info['file_size'] / 1024:.1f} –ö–ë\n"
            f"üìù **–¢–∏–ø:** {'–î–æ–∫—É–º–µ–Ω—Ç' if file_info['file_type'] == 'document' else '–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (—Å–∫–∞–Ω)'}\n\n"
            
            "üîç **–≠—Ç–∞–ø—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏:**\n"
            "‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞\n"
            "‚úÖ –ê–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ\n"
            "‚úÖ –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞\n\n"
            
            "üéâ *–ê–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!*"
        )
        
        try:
            await progress_message.edit_text(
                completion_status,
                parse_mode='Markdown'
            )
        except Exception:
            pass
    
    if analysis_message:
        try:
            await analysis_message.edit_text(
                f"‚úÖ **–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω**\n\n"
                f"{analysis_info['icon']} **{analysis_info['name']}**\n"
                f"üìÑ **–î–æ–∫—É–º–µ–Ω—Ç:** `{file_info['file_name']}`\n\n"
                "üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç –≥–æ—Ç–æ–≤ –∫ –ø—Ä–æ—Å–º–æ—Ç—Ä—É –Ω–∏–∂–µ ‚¨áÔ∏è",
                parse_mode='Markdown'
            )
        except Exception:
            pass
    
    # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π
    keyboard = [
        [
            InlineKeyboardButton("üîÑ –î—Ä—É–≥–æ–π —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞", callback_data="change_analysis_type"),
            InlineKeyboardButton("üìÑ –ù–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç", callback_data="upload_new_document")
        ],
        [
            InlineKeyboardButton("üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="main_menu"),
            InlineKeyboardButton("‚ùå –ó–∞–≤–µ—Ä—à–∏—Ç—å", callback_data="finish_analysis")
        ]
    ]
    
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π —Ä–∞–∑–±–∏–≤–∫–æ–π
    await send_long_message(
        update.callback_query.message.chat,
        analysis_result,
        reply_markup=reply_markup,
        parse_mode='Markdown'
    )
    
    return AnalysisStates.RESULTS_REVIEW.value


async def handle_additional_actions(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π
    """
    query = update.callback_query
    await query.answer()
    
    if query.data == "change_analysis_type":
        # –í–æ–∑–≤—Ä–∞—Ç –∫ –≤—ã–±–æ—Ä—É —Ç–∏–ø–∞ –∞–Ω–∞–ª–∏–∑–∞
        keyboard = []
        for analysis_type, info in ANALYSIS_TYPES.items():
            keyboard.append([InlineKeyboardButton(
                info['name'], 
                callback_data=f"analysis_type_{analysis_type}"
            )])
        
        keyboard.append([InlineKeyboardButton("‚ùå –û—Ç–º–µ–Ω–∞", callback_data="cancel_analysis")])
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        await query.message.reply_text(
            "üéØ **–í—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–≤—ã–π —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞:**",
            reply_markup=reply_markup,
            parse_mode='Markdown'
        )
        
        return AnalysisStates.ANALYSIS_TYPE_SELECTION.value
        
    elif query.data == "upload_new_document":
        # –í–æ–∑–≤—Ä–∞—Ç –∫ –∑–∞–≥—Ä—É–∑–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        return await analyze_command(update, context)
        
    elif query.data == "finish_analysis":
        # –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞
        context.user_data.clear()
        await query.message.reply_text(
            "‚úÖ **–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω**\n\n"
            "–°–ø–∞—Å–∏–±–æ –∑–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ AI-—é—Ä–∏—Å—Ç–∞!\n\n"
            "üîÑ –î–ª—è –Ω–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /analyze\n"
            "üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é: /start",
            parse_mode='Markdown'
        )
        return ConversationHandler.END
    
    elif query.data == "main_menu":
        # –í–æ–∑–≤—Ä–∞—Ç –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é
        context.user_data.clear()
        from bot.handlers import start_command
        return await start_command(update, context)
    
    return AnalysisStates.RESULTS_REVIEW.value


async def cancel_analysis(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """
    –û—Ç–º–µ–Ω–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –≤–æ–∑–≤—Ä–∞—Ç –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é
    """
    # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    context.user_data.clear()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Ç–∫—É–¥–∞ –ø—Ä–∏—à–µ–ª –∑–∞–ø—Ä–æ—Å
    if update.callback_query:
        await update.callback_query.answer()
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é
        user = update.effective_user
        user_name = user.first_name if user.first_name else "–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å"
        
        welcome_message = (
            f"üèõÔ∏è **AI-–Æ—Ä–∏—Å—Ç** ‚Äî –≤–∞—à –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π –ø—Ä–∞–≤–æ–≤–æ–π –ø–æ–º–æ—â–Ω–∏–∫\n\n"
            f"üëã –ü—Ä–∏–≤–µ—Ç, {user_name}!\n\n"
            
            "üéØ **–ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å:**\n"
            "‚Ä¢ 6 –æ—Ç—Ä–∞—Å–ª–µ–π –ø—Ä–∞–≤–∞\n"
            "‚Ä¢ 40+ —Ç–∏–ø–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n"
            "‚Ä¢ –≠–∫—Å–ø–æ—Ä—Ç –≤ Word\n"
            "‚Ä¢ –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π –ø—Ä–æ–≤–µ–¥–µ–Ω–æ: 500+\n\n"
            
            "üíº **–í—ã–±–µ—Ä–∏—Ç–µ –Ω—É–∂–Ω—É—é —É—Å–ª—É–≥—É:**"
        )
        
        # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É –≥–ª–∞–≤–Ω–æ–≥–æ –º–µ–Ω—é
        keyboard = [
            [InlineKeyboardButton("üí¨ –Æ—Ä–∏–¥–∏—á–µ—Å–∫–∞—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è", callback_data="menu_consult")],
            [InlineKeyboardButton("üìÑ –°–æ–∑–¥–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤", callback_data="menu_create")],
            [InlineKeyboardButton("üìä –ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤", callback_data="menu_analyze")],
            [InlineKeyboardButton("‚ÑπÔ∏è –°–ø—Ä–∞–≤–∫–∞ –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∞", callback_data="menu_help")]
        ]
        
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        await update.callback_query.message.reply_text(
            welcome_message,
            reply_markup=reply_markup,
            parse_mode='Markdown'
        )
    else:
        await update.message.reply_text(
            "‚ùå –ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –æ—Ç–º–µ–Ω–µ–Ω.\n"
            "–î–ª—è –Ω–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /analyze"
        )
    
    return ConversationHandler.END


# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏

async def extract_text_from_file(file_info: Dict[str, Any]) -> str:
    """
    –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞
    """
    file_extension = file_info['file_extension'].lower()
    file_type = file_info['file_type']
    
    try:
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        temp_file_path = await download_telegram_file(file_info['file_id'], file_extension)
        
        extracted_text = ""
        
        if file_type == 'document':
            if file_extension in ['.doc', '.docx']:
                extracted_text = await extract_text_from_docx(temp_file_path)
            elif file_extension == '.pdf':
                extracted_text = await extract_text_from_pdf(temp_file_path)
        
        elif file_type == 'image':
            extracted_text = await extract_text_from_image(temp_file_path)
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        if os.path.exists(temp_file_path):
            os.remove(temp_file_path)
        
        # –û—á–∏—â–∞–µ–º –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç
        cleaned_text = clean_extracted_text(extracted_text)
        
        return cleaned_text
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞ {file_info['file_name']}: {e}")
        raise Exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞: {str(e)}")


async def analyze_text_with_gigachat(analysis_type: str, text: str, filename: str = "–¥–æ–∫—É–º–µ–Ω—Ç") -> str:
    """
    –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ GigaChat API
    """
    try:
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç GigaChat
        from ai_gigachat.client import gigachat_client
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ GigaChat API
        logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {filename} —Ç–∏–ø–∞ {analysis_type}")
        
        analysis_result = await gigachat_client.analyze_document(
            document_text=text,
            analysis_type=analysis_type,
            filename=filename
        )
        
        logger.info(f"–ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {filename} —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω")
        return analysis_result
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {filename}: {e}")
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –æ—Ç–≤–µ—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ
        analysis_info = ANALYSIS_TYPES[analysis_type]
        
        return f"""‚ùå **–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞**
{analysis_info['icon']} **{analysis_info['name']}**
üìÑ **–§–∞–π–ª:** {filename}

–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞.

**–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:**
‚Ä¢ –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã —Å AI-—Å–µ—Ä–≤–∏—Å–æ–º
‚Ä¢ –î–æ–∫—É–º–µ–Ω—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –∏–ª–∏ —Å–ª–æ–∂–Ω—ã–π
‚Ä¢ –ü—Ä–æ–±–ª–µ–º—ã —Å —Å–µ—Ç–µ–≤—ã–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ–º

**–ß—Ç–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å:**
‚Ä¢ –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç
‚Ä¢ –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –¥–æ–∫—É–º–µ–Ω—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç
‚Ä¢ –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É, –µ—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º–∞ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è

üîÑ –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞ —Å –∫–æ–º–∞–Ω–¥–æ–π /analyze"""


async def send_long_message(chat, text: str, **kwargs) -> None:
    """
    –£–º–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ –¥–ª–∏–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è —Å —Ä–∞–∑–±–∏–≤–∫–æ–π –Ω–∞ —á–∞—Å—Ç–∏ –ø–æ —Å–º—ã—Å–ª—É
    """
    MAX_MESSAGE_LENGTH = 4096
    
    if len(text) <= MAX_MESSAGE_LENGTH:
        await chat.send_message(text, **kwargs)
        return
    
    # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —Å–º—ã—Å–ª–æ–≤—ã–µ —á–∞—Å—Ç–∏
    parts = smart_split_message(text, MAX_MESSAGE_LENGTH)
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —á–∞—Å—Ç–∏ –ø–æ –æ—á–µ—Ä–µ–¥–∏
    for i, part in enumerate(parts):
        if i == len(parts) - 1:
            # –ü–æ—Å–ª–µ–¥–Ω—è—è —á–∞—Å—Ç—å - —Å –∫–ª–∞–≤–∏–∞—Ç—É—Ä–æ–π
            await chat.send_message(part, **kwargs)
        else:
            # –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —á–∞—Å—Ç–∏ - –±–µ–∑ –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã –∏ —Å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–º –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è
            kwargs_copy = kwargs.copy()
            kwargs_copy.pop('reply_markup', None)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫—Ä–∞—Å–∏–≤—ã–π –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è
            continuation_indicator = f"\n\nüìÑ **–ß–∞—Å—Ç—å {i+1}/{len(parts)}** ‚Ä¢ *–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å–ª–µ–¥—É–µ—Ç...*"
            await chat.send_message(part + continuation_indicator, **kwargs_copy)
            
            # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è
            await asyncio.sleep(0.5)


def smart_split_message(text: str, max_length: int) -> List[str]:
    """
    –£–º–Ω–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ —Å–º—ã—Å–ª—É —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    """
    if len(text) <= max_length:
        return [text]
    
    parts = []
    current_text = text
    
    while len(current_text) > max_length:
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –¥–ª—è —Ä–∞–∑–±–∏–≤–∫–∏ (–æ—Ç –Ω–∞–∏–±–æ–ª–µ–µ –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫ –Ω–∞–∏–º–µ–Ω–µ–µ)
        split_patterns = [
            '\n\n**',          # –ù–æ–≤—ã–π —Ä–∞–∑–¥–µ–ª —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
            '\n**',            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            '\n\n',            # –î–≤–æ–π–Ω–æ–π –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏
            '\n‚Ä¢',             # –°–ø–∏—Å–æ–∫
            '\n-',             # –°–ø–∏—Å–æ–∫ —Å —Ç–∏—Ä–µ
            '\n',              # –û–±—ã—á–Ω—ã–π –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏
            '. ',              # –ö–æ–Ω–µ—Ü –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
            ', ',              # –ó–∞–ø—è—Ç–∞—è
            ' '                # –ü—Ä–æ–±–µ–ª
        ]
        
        split_index = -1
        
        # –ò—â–µ–º –ª—É—á—à–µ–µ –º–µ—Å—Ç–æ –¥–ª—è —Ä–∞–∑–±–∏–≤–∫–∏
        for pattern in split_patterns:
            # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –≤ –¥–æ–ø—É—Å—Ç–∏–º–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ
            temp_index = current_text.rfind(pattern, 0, max_length - 100)  # –û—Å—Ç–∞–≤–ª—è–µ–º –±—É—Ñ–µ—Ä
            if temp_index > max_length // 2:  # –ù–µ —Ä–∞–∑–±–∏–≤–∞–µ–º —Å–ª–∏—à–∫–æ–º —Ä–∞–Ω–æ
                split_index = temp_index + len(pattern)
                break
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ–¥—Ö–æ–¥—è—â–µ–µ –º–µ—Å—Ç–æ, —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω–µ
        if split_index == -1:
            split_index = max_length
        
        # –î–æ–±–∞–≤–ª—è–µ–º —á–∞—Å—Ç—å
        part = current_text[:split_index].strip()
        if part:
            parts.append(part)
        
        # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –æ—Å—Ç–∞–≤—à–µ–º—É—Å—è —Ç–µ–∫—Å—Ç—É
        current_text = current_text[split_index:].strip()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–π—Å—è —Ç–µ–∫—Å—Ç
    if current_text:
        parts.append(current_text)
    
    return parts


# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤

async def download_telegram_file(file_id: str, file_extension: str) -> str:
    """
    –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –∏–∑ Telegram –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    """
    from telegram import Bot
    from config import TELEGRAM_TOKEN
    
    bot = Bot(token=TELEGRAM_TOKEN)
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ
    file = await bot.get_file(file_id)
    
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    temp_dir = tempfile.gettempdir()
    temp_file_path = os.path.join(temp_dir, f"telegram_file_{file_id}{file_extension}")
    
    # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
    await file.download_to_drive(temp_file_path)
    
    return temp_file_path


async def extract_text_from_docx(file_path: str) -> str:
    """
    –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ DOCX —Ñ–∞–π–ª–∞
    """
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
        doc = DocxDocument(file_path)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –≤—Å–µ—Ö –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤
        text_parts = []
        for paragraph in doc.paragraphs:
            if paragraph.text.strip():
                text_parts.append(paragraph.text.strip())
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ç–∞–±–ª–∏—Ü
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    if cell.text.strip():
                        text_parts.append(cell.text.strip())
        
        extracted_text = '\n'.join(text_parts)
        
        if not extracted_text.strip():
            raise Exception("–î–æ–∫—É–º–µ–Ω—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞ –∏–ª–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω")
        
        return extracted_text
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ DOCX: {e}")
        raise Exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å DOCX —Ñ–∞–π–ª: {str(e)}")


async def extract_text_from_pdf(file_path: str) -> str:
    """
    –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF —Ñ–∞–π–ª–∞ (—Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π OCR –¥–ª—è —Å–∫–∞–Ω–æ–≤)
    """
    extracted_text = ""
    
    try:
        # –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –Ω–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ PyMuPDF (–±—ã—Å—Ç—Ä–µ–µ)
        pdf_document = fitz.open(file_path)
        
        for page_num in range(pdf_document.page_count):
            page = pdf_document.get_page(page_num)
            page_text = page.get_text()
            
            if page_text.strip():
                extracted_text += f"\n--- –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num + 1} ---\n{page_text}\n"
        
        pdf_document.close()
        
        # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if len(extracted_text.strip()) > 50:
            return extracted_text
        
        # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç–∞ –º–∞–ª–æ, –ø—Ä–æ–±—É–µ–º OCR
        logger.info("–ú–∞–ª–æ —Ç–µ–∫—Å—Ç–∞ –≤ PDF, –ø—ã—Ç–∞–µ–º—Å—è OCR...")
        ocr_text = await extract_text_from_pdf_with_ocr(file_path)
        
        return ocr_text if ocr_text else extracted_text
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF: {e}")
        
        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ —á–µ—Ä–µ–∑ PyPDF2
        try:
            return await extract_text_from_pdf_pypdf2(file_path)
        except Exception as e2:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–∑ PDF: {e2}")
            raise Exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å PDF —Ñ–∞–π–ª: {str(e)}")


async def extract_text_from_pdf_pypdf2(file_path: str) -> str:
    """
    –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF —á–µ—Ä–µ–∑ PyPDF2
    """
    try:
        with open(file_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            
            text_parts = []
            for page_num in range(len(pdf_reader.pages)):
                page = pdf_reader.pages[page_num]
                page_text = page.extract_text()
                
                if page_text.strip():
                    text_parts.append(f"--- –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num + 1} ---\n{page_text}")
            
            extracted_text = '\n'.join(text_parts)
            
            if not extracted_text.strip():
                raise Exception("PDF –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–∑–≤–ª–µ–∫–∞–µ–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞")
            
            return extracted_text
            
    except Exception as e:
        raise Exception(f"–û—à–∏–±–∫–∞ PyPDF2: {str(e)}")


async def extract_text_from_pdf_with_ocr(file_path: str) -> str:
    """
    –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF —Å –ø–æ–º–æ—â—å—é OCR (–¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Tesseract
        if not is_tesseract_available():
            raise Exception("OCR –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: —Ç—Ä–µ–±—É–µ—Ç—Å—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ Tesseract OCR")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        from pdf2image import convert_from_path
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        images = convert_from_path(file_path, dpi=300, fmt='jpeg')
        
        text_parts = []
        for i, image in enumerate(images):
            # –ü—Ä–∏–º–µ–Ω—è–µ–º OCR –∫ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
            page_text = pytesseract.image_to_string(image, lang='rus+eng')
            
            if page_text.strip():
                text_parts.append(f"--- –°—Ç—Ä–∞–Ω–∏—Ü–∞ {i + 1} ---\n{page_text}")
        
        extracted_text = '\n'.join(text_parts)
        
        if not extracted_text.strip():
            raise Exception("OCR –Ω–µ —Å–º–æ–≥ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ç–µ–∫—Å—Ç –≤ PDF")
        
        return extracted_text
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ OCR –¥–ª—è PDF: {e}")
        raise Exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ç–µ–∫—Å—Ç –≤ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–º PDF: {str(e)}")


async def extract_text_from_image(file_path: str) -> str:
    """
    –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é OCR
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Tesseract
        if not is_tesseract_available():
            raise Exception("OCR –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: —Ç—Ä–µ–±—É–µ—Ç—Å—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ Tesseract OCR.\n"
                          "–î–ª—è Windows: —Å–∫–∞—á–∞–π—Ç–µ —Å https://github.com/UB-Mannheim/tesseract/wiki\n"
                          "–î–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Tesseract OCR –≤ —Å–∏—Å—Ç–µ–º–µ.")
        
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image = Image.open(file_path)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º OCR
        extracted_text = pytesseract.image_to_string(image, lang='rus+eng')
        
        if not extracted_text.strip():
            raise Exception("OCR –Ω–µ —Å–º–æ–≥ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏")
        
        return extracted_text
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ OCR –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        raise Exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏: {str(e)}")


def is_tesseract_available() -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Tesseract OCR
    """
    try:
        import subprocess
        result = subprocess.run(['tesseract', '--version'], 
                              capture_output=True, text=True, timeout=10)
        return result.returncode == 0
    except (subprocess.TimeoutExpired, subprocess.CalledProcessError, FileNotFoundError):
        return False


def clean_extracted_text(text: str) -> str:
    """
    –û—á–∏—Å—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
    """
    if not text:
        return ""
    
    # –ó–∞–º–µ–Ω—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –Ω–∞ –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ (–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫)
    cleaned = re.sub(r'[ \t]+', ' ', text)
    
    # –£–¥–∞–ª—è–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ (–±–æ–ª—å—à–µ 2 –ø–æ–¥—Ä—è–¥)
    cleaned = re.sub(r'\n\s*\n\s*\n+', '\n\n', cleaned)
    
    # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫
    lines = [line.strip() for line in cleaned.split('\n')]
    cleaned = '\n'.join(lines)
    
    # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ –≤—Å–µ–≥–æ —Ç–µ–∫—Å—Ç–∞
    cleaned = cleaned.strip()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É
    if len(cleaned) < 10:
        raise Exception("–ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π")
    
    return cleaned 